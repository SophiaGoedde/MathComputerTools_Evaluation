---
title: "ComputerTools_Evaluation"
author: "Sophia Gödde"
format: html
editor: visual
bibliography: references.bib
---

# Code RQ 1

## Data exploration

```{r cars}
#non-relevant results were deleted
library(tidyverse) 
library(corrplot) # For correlation plots
library(FactoMineR) # For PCA
library(factoextra) # For PCA plots
library(vegan) # For CCA
library(GGally) #for multiple scatterplots (function ggpairs)
library(rsample) # For sampling of data (split, analysis,..)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(class) # For k-NN (function knn)
library(rsample) # For resampling (split, analysis,..)
library(caret)

# Load dataset
lizard2 <- read.csv("lizard2.csv")

# rename columns 
names(lizard2) <- c(
  "Species",
  "Genus",
  "Family",
  "Population",
  "Longitude",
  "Latitude",
  "AFWeight",              # Average Female adult weight (g)
  "SDFAWeight",              # SD Female adult weight (g)
  "SampleFAWeight",          # Sample Size Female adult weight
  "MeanFSVL",                # Mean Female SVL adults (mm)
  "SDFSVL",               # Standard deviation Female SVL adults (mm)
  "SampleFSVL",              # Sample size Mean Female SVL adults
  "FSVL_mature",          # Female SVL at maturity (mm)
  "OffspringSVL",         # Offspring SVL (mm)
  "MeanClutch",              # Mean Clutch Size
  "SampleClutch",            # Sample size for Clutch Size
  "ReproductionMode",        # Mode of reproduction
  "ClutchesPerYear",         
  "ClutchFreq",              # Clutch Frequency
  "RCM",                     
  "ForagingMode",           
  "Distribution",            
  "Habitat_Type",            
  "Source"                   
)

# Select relevant columns & remove na
sublizard <- lizard2 %>%
  select(Habitat_Type, Latitude, MeanFSVL) %>%
  drop_na()
# From 740 to 686 observations 

# make latitude absolute - I THINK NO
# sublizard$Latitude = abs(sublizard$Latitude)

# summary and check dataset (especially concerning continous and categorical variables)
summary(sublizard)

#Change habitat type to numercial values (1-8)
sublizard$Habitat_Type = as.factor(sublizard$Habitat_Type)

# Scaling Latitude and SVL 
sublizard_scaled <- sublizard %>%
  mutate(
    Latitude = scale(Latitude),
    MeanFSVL = scale(MeanFSVL))

# Checking Data: Boxplot for relationship between mean female SVL and Habitat Type. Same is done for 
boxplot(MeanFSVL ~ Habitat_Type, data = lizard2,
        main = "SVL Mean by Habitat Type", xlab = "Habitat Type", ylab = "Mean Female SVL ")

boxplot(Latitude ~ Habitat_Type, data = lizard2,
        main = "Latitude by Habitat Type", xlab = "Habitat Type", ylab = "Latitude")
# for a few habitat types a clear difference can be seen 

#Distribution - Pairs plot with correlation
GGally::ggpairs(sublizard, aes(color = Habitat_Type))

# Visualization: SVL & Latitude -> Habitat Type
# habitat ~ SVL
ggplot(sublizard, aes(x = Habitat_Type, y = MeanFSVL, fill = Habitat_Type)) +
  geom_boxplot() + theme_bw()
# # It does not seem like SVL has an impact on habitat type - similar distributed. 

# habitat ~ latitude 
ggplot(sublizard, aes(x = Habitat_Type, y = Latitude, fill = Habitat_Type)) +
  geom_boxplot() + theme_bw()

```

## KNN and cross validation

```{r}
### KNN ###########
set.seed(123)
# Plot data 
ggplot(sublizard) +
aes(x = MeanFSVL, y = Latitude, color = Habitat_Type) +
geom_point() +
labs(x='Mean SVL'
,y='Latitude')
#INTERPRETATION 
#Pattern Terrestrial accumulation around -5 ; -25 and 25. 
# Saxicolous: accumulation at -10 and 15. 

# Random splitting of test and training data randomly (90-10%) with rsample package 
split <- initial_split(sublizard, prop = 0.8)
train_set <- analysis(split)
dim(train_set); head(train_set)

test_set <- assessment(split)
dim(test_set); head(test_set)


### First KNN classifier with k 15

#removing the Habitat_Type column (response) since train and test must only contain predictors. 
# The response for the training data set is given in the ‘cl’ argument

### Test classifier on test set 
first_knn <- knn(train = select(train_set,-Habitat_Type),
test = select(test_set,-Habitat_Type),
cl = train_set$Habitat_Type,
k = 15, 
prob = TRUE)

### Confusion matrix 
first_confusion_matrix <- table(Predicted = first_knn,
True = test_set$Habitat_Type)
first_confusion_matrix
# INTERPRETATION: Terrestrial was 86 times truly predicted. No other Hbaitat Type was truly predicted. Aboreal and Saxicolous Habitats where 26 and 18 times falsy predicted as Terrestrial. The table shows that every new Hbaitat predicted was predicted as Terrestrial, which is very bad... This shows that the model was not good. Reasons for this are highly probable the unbalanced dataset. Further explanations below. 

#Metrics to assess quality of clssifier

### Check accuracy of first classifier 
sum(diag(first_confusion_matrix)) / sum(first_confusion_matrix)

### Cross validation for choice of k
# Defining how many folds (10 folds means splitting dataset into 10 equal parts. The model is trained on 9 parts and tested on the remaining 1, this is repeated 10 times (every time with a different fold). 
ctrl <- trainControl(method = "cv", verboseIter = FALSE, number = 10) 

# knn fit with centering and scaling all numeric variables for distance calculations
knnFit <- train(Habitat_Type~.,
                data = train_set,
                method = "knn",
                trControl = ctrl ,
                preProcess = c("center", "scale"),
                tuneGrid = expand.grid(k = 1:50))
plot(knnFit)
# Plot shows development of accuracy according to the number of neighbours chosen (train dataset contains 10% of all data)

### CV accuracy if highest for which k
k_best <- knnFit$bestTune$k
k_best
#This best k value changes all the time depending on test and train data (randomly distributed)
# Best k: 20


### Now running KNN with best k fit of the train set
best_knn <- knn(train = select(train_set,-Habitat_Type),
                test = select(test_set,-Habitat_Type),
                cl = train_set$Habitat_Type,
                k = k_best,
                prob = TRUE)
best_confusion_matrix <- table(Predicted = best_knn,
                               True = test_set$Habitat_Type) 
best_confusion_matrix
# Now the confusion matrix shows a bit better results. The habitat types Saxicolous and Aboreal were, additional to 48 correct predictions for Terrestrial, two times each correctly predicted. However, the terrestrial habitat type was 5 times falsy positive predicted. 
accuracy_best <- sum(diag(best_confusion_matrix)) / sum(best_confusion_matrix)
accuracy_best
# 0.5652174


### Plotting the results
# Predict zone of influence for each class –> define a prediction grid
# To know the range check data raneg of SVL and Latitude first
range(sublizard$MeanFSVL)
# 21.397 312.100
range(sublizard$Latitude)
# 0.29 51.35

# Prediction grid with min and max values of predictors
grid_prediction <- expand.grid(
  MeanFSVL = seq(min(sublizard$MeanFSVL), max(sublizard$MeanFSVL), length.out = 200),
  Latitude = seq(min(sublizard$Latitude), max(sublizard$Latitude), length.out = 200)
)
grid_prediction

### Predcition grid for the chosen k (20) 
# using all data (reunite train and test data
predicted_Habitat <- knn(train = select(CSVLH_lizard,-Habitat_Type), 
test = grid_prediction, 
k = k_best, 
cl = CSVLH_lizard$Habitat_Type, 
prob = TRUE) 
# Prob=TRUE for the uncertainty associated with estimation (coded as attribute of prediction vector) # This attribute now has to be extracted 
proba_Habitat <- attr(predicted_Habitat, "prob")
proba_Habitat
# Final-result in table 
final_predictions <- grid_prediction %>%
mutate(Habitat_Type = predicted_Habitat,
Probability = proba_Habitat)
summary(final_predictions)
final_predictions
# INTERPRETATION: only the first three habitats were predicted (Terretrial 38600 times, Aboreal 903 times and Saxicolous 497 times). 

# mean predictions per class 
class(final_predictions)
str(final_predictions)
head(final_predictions)

### Plotting predictions 
ggplot(final_predictions) +
  aes(x = MeanFSVL, y = Latitude) +
  geom_raster(aes(fill = Habitat_Type), alpha = 0.6) +
  geom_point(data = sublizard, aes(color = Habitat_Type), size = 1.5) +
  labs(
    x = 'Mean SVL',
    y = 'Latitude',
    title = 'KNN-Predicted Habitat Types'
  ) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0))
# INTERPRETATION: The graph shows that almost all predictions are terrestrial which shows for a very unbalanced model due to an extramly unbalanced dataset and potentially too weak predictors too. 


### Present uncertainty with predictors 
# Uncertainty is the frequency of neighbors not belonging to the predicted class among all the neighbors.
ggplot(final_predictions) +
aes(x = MeanFSVL, y = Latitude) +
geom_raster(aes(fill = 1- proba_Habitat)) + # =uncertainty
geom_point(data = sublizard, aes(color = Habitat_Type)) +
labs(x = "Mean Female SVL", y = "Latitude", title = "KNN-Habitat Prediction uncertainty",
fill = "Uncertainty") +
scale_x_continuous(expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
scale_fill_gradient(low = "white", high = "darkred")
# INTERPRETATION: The classifier learned nothing about the havitat type. The uncertainry is the same almost everywhere and very high. (mostly over 0.5), which indicated a high uncertainty and therefore a bad prediction. Reasons for this stated below (Class imbalance in dataset and probably too few predictors). 
# The model is biased towards the majority class. 
```

## Random Forest

```{r}
# Loading required packages and data.
library(tidyverse)
library(rsample) 
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret) 
library(themis) 
library(permute)
library(recipes)

# Same Dataset 
RF_sublizard <- lizard2 %>%
  select(Habitat_Type, Latitude, MeanFSVL) %>%
  drop_na()
# Important to convert categorical variables to factors (Habitat Type, but have done that above already)
RF_sublizard$Habitat_Type <- as.factor(RF_sublizard$Habitat_Type)

### Splitting dataset into train and test data the same way as KNN 
# Why: To compare the results and the show the robustness of algorithm and to later compare results of accuracy with KNN. 
train_RF_lizard <- train_set
test_RF_lizard  <- test_set



#### Choosing hyperparameters with cross-validation 
parameters_CV_lizard <- trainControl(method = "repeatedcv",
                          number = 10,
                          repeats = 5)
# For all the available methods (and the necessary arguments), please refer to help.
rf_grid <- expand.grid(mtry = 1:2) # because 2 variables 

predictor_forest <- caret::train(Habitat_Type ~., 
                                 data = train_RF_lizard, 
                                 method = "rf", 
                                 metric = "Accuracy",
                                 trControl = parameters_CV_lizard, 
                                 tuneGrid = rf_grid,
                                 ntree = 500)
predictor_forest 
# chosen mtry was 1 

# Visualize cross-validation results of mtry 
as.data.frame(predictor_forest$results) %>%
ggplot(aes(x = mtry, y = Accuracy)) +
geom_point()

# Aggregate performance results into an object to use later 
my_predictions <- predict(predictor_forest, newdata = select(test_RF_lizard,- Habitat_Type))
my_predictions

# Contingence table
table(prediction = my_predictions, truth = test_RF_lizard$Habitat_Type)

###### I will run three RF: normal (imbalanced) dataset, weightened and balanced 
```

#### 1) RF with normal/baseline data (imbalanced)

```{r}

forest_lizard_base <- randomForest(
  Habitat_Type ~.,
  data = train_RF_lizard, 
  ntree = 500,
  maxnodes = 10,
  mtry = 1,
  importance = TRUE)

# Predictions
rf_pred_base <- predict(
  forest_lizard_base,
  newdata = select(test_RF_lizard, -Habitat_Type))

# Accuracy
acc_base <- predict(forest_lizard, newdata = select(test_RF_lizard,- Habitat_Type)) %>% 
  table(prediction = ., truth = test_RF_lizard$Habitat_Type) %>%
  {sum(diag(.)) / sum(.)}
#0.6043165

# Look at Confusion Matrix 
conf_base <- table(prediction = rf_pred_base,
                       truth = test_RF_lizard$Habitat_Type)
conf_base
# A few rare habitats were correctly predicted:
# Arboreal: 6 correct & Saxicolous: 1 correct
# This is already better than KNN, which predicted 0 for all rare habitats but still very weak. Therefore weighnted class 

### Chechking variable importance 
varImpPlot(forest_lizard)
# Latitude more important in predicting Habitat Type than Mean SVL. 
```

#### 2) RF with wheightened classes

```{r}
# Loosing data from terrestrial class to match closer with rare habitats. Downside: loosing a lot of data and since small groups are VERY small this might lead to even more inaccuracy. Upsampling of rare classed could lead to over-fitting. 

# Calculate class weights (inverse frequency → more weight to rare habitats)
class_weights <- 1 / table(train_RF_lizard$Habitat_Type)
class_weights <- class_weights / sum(class_weights)

# RF with weightened classes 
forest_lizard_weighted <- randomForest(
  Habitat_Type ~ .,
  data = train_RF_lizard,
  ntree = 500,
  mtry = 1,
  importance = TRUE,
  classwt = class_weights)


# Predictions
rf_pred_weighted <- predict(
  forest_lizard_weighted,
  newdata = select(test_RF_lizard, -Habitat_Type))

# Accuracy 
acc_weighted <- predict(forest_lizard_weighted, newdata = select(test_RF_lizard,- Habitat_Type)) %>%
table(prediction = ., truth = test_RF_lizard$Habitat_Type) %>%
  {sum(diag(.)) / sum(.)}
acc_weighted
# 0.5539568

# Look at Confusion Matrix 
conf_weighted <- table(prediction = rf_pred_weighted,
                       truth = test_RF_lizard$Habitat_Type)
conf_weighted
# A bit better but still strong bias towards terrestrial. 
# correctly predicts more Arboreal and Saxicolous individuals (7 and 8 true positives, respectively, vs. 6 and 1 in base prediction). 
# but still many habitat types undetected. 
# Aquatic, Bromelicolous, Fossorial, Psammophilus, and Semi-arboreal have zero true positives
```

#### 3) RF with downsampling

```{r}
# Downsample the training data by reducing terrestrial class
train_down <- downSample(
  x = select(train_RF_lizard, -Habitat_Type),
  y = train_RF_lizard$Habitat_Type,
  yname = "Habitat_Type")
# Already not good since all classes end up with only 2 samples
# cannot be used! 

table(train_down$Habitat_Type)
# now all have only 2 observations - very likely that this is too few! 
# Upsampling might be a better solution with this dataset. 

# RF with downsampled data 
forest_lizard_down <- randomForest(
  Habitat_Type ~ .,
  data = train_down,
  ntree = 500,
  mtry = 1,
  importance = TRUE
)

# Predictions on original test set
rf_pred_down <- predict(forest_lizard_down,
                        newdata = select(test_RF_lizard, -Habitat_Type))
rf_pred_down
# Confusion matrix
conf_down <- table(prediction = rf_pred_down,
                   truth = test_RF_lizard$Habitat_Type)
conf_down
# True positives: Arboreal: 6 ; Saxicolous: 3 ; Fossorial: 1 ; Semi-arboreal: 1 ; Psammophilus: 1 ; Aquatic: 3 ; Bromelicolous: 0 (still too rare)
# But more missclassification bcs 90% of dataset (terrestrial) was removed to match the samll sampled
# Therefore: overfitting to the downsampled minority classes.

# Accuracy
acc_down <- sum(diag(conf_down)) / sum(conf_down)
acc_down
# 0.1870504
# Very low accuracy. So more rare habitats were predicted but many of them might be falsly predicted. 

```

#### 4) RF with upsampled data

Upsampling can lead to overfitting. However, it might be a good idea to just try and see since otherwise rare classes are so small, that they disappear during training. CAREFUL INTERPRETATION!

```{r}
# Upsample the training data by duplicating minority classes
train_up <- upSample(
  x = select(train_RF_lizard, -Habitat_Type),
  y = train_RF_lizard$Habitat_Type,
  yname = "Habitat_Type")

table(train_up$Habitat_Type)
# Now all have 332 observations. 

# RF on upsampled data
forest_lizard_up <- randomForest(
  Habitat_Type ~ .,
  data = train_up,
  ntree = 500,
  mtry = 1,
  importance = TRUE)

# Predictions on original test set
rf_pred_up <- predict(forest_lizard_up,
                      newdata = select(test_RF_lizard, -Habitat_Type))

# Confusion matrix
conf_up <- table(prediction = rf_pred_up,
                 truth = test_RF_lizard$Habitat_Type)
conf_up

# Accuracy
acc_up <- sum(diag(conf_up)) / sum(conf_up)
acc_up
# 0.5107914
```

#### Comparing 4 RF models

```{r}
# Comparison of all 4 Random Forest models
rf_comparison <- data.frame(
  Model = c("Baseline RF", "Class-Weighted RF", "Downsampled RF", "Upsampled RF"),
  Accuracy = c(acc_base, acc_weighted, acc_down, acc_up))
rf_comparison

# Visualize results 
ggplot(rf_comparison, aes(x = Model, y = Accuracy, fill = Model)) +
  geom_col() +
  theme_minimal() +
  coord_flip() +
  labs(title = "Comparison of Random Forest Models",
       y = "Accuracy",
       x = "")
# Baseline RF achieved highest accuracy but its because its bias towrads terrestrial class and no detection of rare classes.
```

## Comparing RF & KNN 

```{r}
## Comparison: KNN & RF
cm_knn_RF <- confusionMatrix(
  data      = best_knn_RF,
  reference = y_test_RF)

cm_rf_RF <- confusionMatrix(
  data      = rf_pred_RF,
  reference = y_test_RF)

# get mean balanced accuracy across classes
balacc <- function(cm) {
  mean(cm$byClass[, "Balanced Accuracy"], na.rm = TRUE)}

results_compare <- data.frame(
  Model            = c("KNN", "Random Forest"),
  Accuracy         = c(cm_knn_RF$overall["Accuracy"],
                       cm_rf_RF$overall["Accuracy"]),
  Kappa            = c(cm_knn_RF$overall["Kappa"],
                       cm_rf_RF$overall["Kappa"]),
  BalancedAccuracy = c(balacc(cm_knn_RF),
                       balacc(cm_rf_RF)))

results_compare
# 
```

#### Extra: RF for Habitat Groups

##### RF groups - Weighted classes

```{r}
# Just to see/get an idea: Predicting three habitat categories (grouped into three) by more ecological variables just to see what is more important: imbalanced data or the need for more ecological variables.#

# Grouping all 8 habitats into 3 groups 
# Recode broad habitat classes
lizard2 <- lizard2 %>%
  mutate(Habitat_Broad = case_when(
      Habitat_Type %in% c("Terrestrial", "Fossorial") ~ "Ground",
      Habitat_Type %in% c("Saxicolous", "Psammophilus") ~ "Rock",
      Habitat_Type %in% c("Arboreal", "Semi-arboreal", "Bromelicolous", "Aquatic") ~ "Above",
      TRUE ~ NA_character_))

# Convert to factor
lizard2$Habitat_Broad <- factor(lizard2$Habitat_Broad,
                                levels = c("Ground", "Rock", "Above"))

# delete na 
rf_data <- lizard2 %>%
  select(
    Habitat_Broad,
    MeanFSVL,
    AFWeight,
    FSVL_mature,
    MeanClutch,
    Latitude,
    ForagingMode,
    ReproductionMode) %>%
  drop_na()

# Make sure categorical predictors are factors
rf_data$ForagingMode      <- as.factor(rf_data$ForagingMode)
rf_data$ReproductionMode  <- as.factor(rf_data$ReproductionMode)
rf_data$Habitat_Broad     <- droplevels(rf_data$Habitat_Broad)

summary(rf_data$Habitat_Broad)


# Train and test split for RF 
set.seed(123)  # for reproducibility

split_rf <- initial_split(rf_data, prop = 0.8,
                          strata = "Habitat_Broad")

train_rf <- analysis(split_rf)
test_rf  <- assessment(split_rf)

table(train_rf$Habitat_Broad)
table(test_rf$Habitat_Broad)

# class weights to handle existing imbalance 
class_weights <- 1 / table(train_rf$Habitat_Broad)
class_weights <- class_weights / sum(class_weights)

class_weights


# Fit class weighted RF 
set.seed(123)

rf_broad <- randomForest(
  Habitat_Broad ~ MeanFSVL + AFWeight + FSVL_mature +
                  MeanClutch + Latitude +
                  ForagingMode + ReproductionMode,
  data = train_rf,
  ntree = 500,
  mtry = 1,          
  importance = TRUE,
  classwt = class_weights)

print(rf_broad)

##### Predictions and confusion matrix 
# Predictions
pred_broad <- predict(rf_broad, newdata = test_rf)

# Confusion matrix
conf_broad <- table(
  Prediction = pred_broad,
  Truth      = test_rf$Habitat_Broad
)
conf_broad

# Accuracy
acc_broad <- sum(diag(conf_broad)) / sum(conf_broad)
acc_broad

# More detailed metrics
confusionMatrix(pred_broad, test_rf$Habitat_Broad)

#### Which variable has biggest importance
varImpPlot(rf_broad,
           main = "Variable Importance for Broad Habitat Classes")

```

##### RF groups - Baseline data

```{r}
set.seed(123)

rf_broad_base <- randomForest(
  Habitat_Broad ~ MeanFSVL + AFWeight + FSVL_mature +
                  MeanClutch + Latitude +
                  ForagingMode + ReproductionMode,
  data = train_rf,
  ntree = 500,
  mtry = 1,
  importance = TRUE
)

pred_broad_base <- predict(rf_broad_base, newdata = test_rf)

conf_broad_base <- table(
  Prediction = pred_broad_base,
  Truth      = test_rf$Habitat_Broad
)
conf_broad_base

acc_broad_base <- sum(diag(conf_broad_base)) / sum(conf_broad_base)
acc_broad_base

confusionMatrix(pred_broad_base, test_rf$Habitat_Broad)

```

##### Compare baseline and weighted

Results Baseline: Ground: very well detected (Sensitivity ≈ 0.89), but **specificity is low** (0.57), meaning many Rock/Above species are misclassified

```{r}
rf_compare_broad <- data.frame(
  Model    = c("Baseline RF (Broad)", "Weighted RF (Broad)"),
  Accuracy = c(acc_broad_base, acc_broad)
)
rf_compare_broad
#Broad habitat classes (Ground vs Rock vs Above) can be predicted with ~66–71% accuracy from morphology, reproduction, foraging mode and latitude, but even with class weighting the model remains strongly biased toward Ground habitats, and Above-ground species are still hard to distinguish.
```

> 
